{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "elect-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from transformer.tokenization import BertTokenizer\n",
    "from transformer.modeling import TinyBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "micro-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from task_distill import (\n",
    "    ColaProcessor,\n",
    "    MnliProcessor,\n",
    "    MnliMismatchedProcessor,\n",
    "    MrpcProcessor,\n",
    "    Sst2Processor,\n",
    "    StsbProcessor,\n",
    "    QqpProcessor,\n",
    "    QnliProcessor,\n",
    "    RteProcessor,\n",
    "    WnliProcessor,\n",
    ")\n",
    "from task_distill import convert_examples_to_features, get_tensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acting-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = {\n",
    "    \"cola\": ColaProcessor,\n",
    "    \"mnli\": MnliProcessor,\n",
    "    \"mnli-mm\": MnliMismatchedProcessor,\n",
    "    \"mrpc\": MrpcProcessor,\n",
    "    \"sst-2\": Sst2Processor,\n",
    "    \"sts-b\": StsbProcessor,\n",
    "    \"qqp\": QqpProcessor,\n",
    "    \"qnli\": QnliProcessor,\n",
    "    \"rte\": RteProcessor,\n",
    "    \"wnli\": WnliProcessor\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "manual-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_modes = {\n",
    "    \"cola\": \"classification\",\n",
    "    \"mnli\": \"classification\",\n",
    "    \"mnli-mm\": \"classification\",\n",
    "    \"mrpc\": \"classification\",\n",
    "    \"sst-2\": \"classification\",\n",
    "    \"sts-b\": \"regression\",\n",
    "    \"qqp\": \"classification\",\n",
    "    \"qnli\": \"classification\",\n",
    "    \"rte\": \"classification\",\n",
    "    \"wnli\": \"classification\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-wright",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cathedral-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'mnli'\n",
    "processor = processors[task_name]()\n",
    "output_mode = output_modes[task_name]\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)\n",
    "teacher_model_path = '/home/mcao610/scratch/huggingface/MNLI/uncased/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cleared-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/mcao610/scratch/glue_data/MNLI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "absent-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- train examples: 392702\n",
      "- dev examples: 9815\n",
      "- dev mismatched examples: 9832\n"
     ]
    }
   ],
   "source": [
    "examples = []\n",
    "train_examples = processor.get_train_examples(data_dir)\n",
    "dev_examples = processor.get_dev_examples(data_dir)\n",
    "print('- train examples: {}'.format(len(train_examples)))\n",
    "print('- dev examples: {}'.format(len(dev_examples)))\n",
    "examples.extend(train_examples)\n",
    "examples.extend(dev_examples)\n",
    "\n",
    "if task_name == 'mnli':\n",
    "    processor = processors['mnli-mm']()\n",
    "    dev_mismatched_examples = processor.get_dev_examples(data_dir)\n",
    "    print('- dev mismatched examples: {}'.format(len(dev_mismatched_examples)))\n",
    "    examples.extend(dev_mismatched_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "olympic-wellington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412349"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f070e80a-ec9c-48fa-b8a7-28550614ea75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<task_distill.InputExample at 0x2b4876767490>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551ed294-091f-41a8-9db5-1de433594853",
   "metadata": {},
   "source": [
    "#### Convert Examples to Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "379b3f63-84bb-4537-903c-d107a7d9759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_guids = []\n",
    "\n",
    "for e in examples:\n",
    "    train_guids.append(e.guid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "manual-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(teacher_model_path, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suitable-texture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/14 09:44:17 AM Writing example 0 of 412349\n",
      "09/14 09:44:18 AM *** Example ***\n",
      "09/14 09:44:18 AM guid: train-0\n",
      "09/14 09:44:18 AM tokens: [CLS] conceptual ##ly cream ski ##mming has two basic dimensions - product and geography . [SEP] product and geography are what make cream ski ##mming work . [SEP]\n",
      "09/14 09:44:18 AM input_ids: 101 17158 2135 6949 8301 25057 2038 2048 3937 9646 1011 4031 1998 10505 1012 102 4031 1998 10505 2024 2054 2191 6949 8301 25057 2147 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "09/14 09:44:18 AM input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "09/14 09:44:18 AM segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "09/14 09:44:18 AM label: neutral\n",
      "09/14 09:44:18 AM label_id: 1\n",
      "09/14 09:44:22 AM Writing example 10000 of 412349\n",
      "09/14 09:44:27 AM Writing example 20000 of 412349\n",
      "09/14 09:44:31 AM Writing example 30000 of 412349\n",
      "09/14 09:44:36 AM Writing example 40000 of 412349\n",
      "09/14 09:44:40 AM Writing example 50000 of 412349\n",
      "09/14 09:44:44 AM Writing example 60000 of 412349\n",
      "09/14 09:44:49 AM Writing example 70000 of 412349\n",
      "09/14 09:44:54 AM Writing example 80000 of 412349\n",
      "09/14 09:44:58 AM Writing example 90000 of 412349\n",
      "09/14 09:45:03 AM Writing example 100000 of 412349\n",
      "09/14 09:45:07 AM Writing example 110000 of 412349\n",
      "09/14 09:45:12 AM Writing example 120000 of 412349\n",
      "09/14 09:45:17 AM Writing example 130000 of 412349\n",
      "09/14 09:45:21 AM Writing example 140000 of 412349\n",
      "09/14 09:45:25 AM Writing example 150000 of 412349\n",
      "09/14 09:45:30 AM Writing example 160000 of 412349\n",
      "09/14 09:45:34 AM Writing example 170000 of 412349\n",
      "09/14 09:45:39 AM Writing example 180000 of 412349\n",
      "09/14 09:45:44 AM Writing example 190000 of 412349\n",
      "09/14 09:45:48 AM Writing example 200000 of 412349\n",
      "09/14 09:45:53 AM Writing example 210000 of 412349\n",
      "09/14 09:45:57 AM Writing example 220000 of 412349\n",
      "09/14 09:46:02 AM Writing example 230000 of 412349\n",
      "09/14 09:46:06 AM Writing example 240000 of 412349\n",
      "09/14 09:46:10 AM Writing example 250000 of 412349\n",
      "09/14 09:46:16 AM Writing example 260000 of 412349\n",
      "09/14 09:46:20 AM Writing example 270000 of 412349\n",
      "09/14 09:46:25 AM Writing example 280000 of 412349\n",
      "09/14 09:46:29 AM Writing example 290000 of 412349\n",
      "09/14 09:46:33 AM Writing example 300000 of 412349\n",
      "09/14 09:46:38 AM Writing example 310000 of 412349\n",
      "09/14 09:46:42 AM Writing example 320000 of 412349\n",
      "09/14 09:46:47 AM Writing example 330000 of 412349\n",
      "09/14 09:46:51 AM Writing example 340000 of 412349\n",
      "09/14 09:46:57 AM Writing example 350000 of 412349\n",
      "09/14 09:47:02 AM Writing example 360000 of 412349\n",
      "09/14 09:47:06 AM Writing example 370000 of 412349\n",
      "09/14 09:47:11 AM Writing example 380000 of 412349\n",
      "09/14 09:47:15 AM Writing example 390000 of 412349\n",
      "09/14 09:47:20 AM Writing example 400000 of 412349\n",
      "09/14 09:47:24 AM Writing example 410000 of 412349\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 128\n",
    "train_features = convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, output_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "operating-vietnamese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412349\n",
      "<task_distill.InputFeatures object at 0x2b48f0c8c150>\n"
     ]
    }
   ],
   "source": [
    "print(len(train_features))\n",
    "print(train_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "overall-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, all_label_ids = get_tensor_data(output_mode, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "following-least",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.TensorDataset"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "pursuant-russian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([412349, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34099907-8522-44cf-8c97-dd959b3e45b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([412349])\n",
      "tensor([1, 0, 0, 0, 1, 0, 1, 0, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(all_label_ids.shape)\n",
    "print(all_label_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "indie-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, sampler=SequentialSampler(train_data), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-airfare",
   "metadata": {},
   "source": [
    "#### Load Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unsigned-candidate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/14 09:47:29 AM Model config {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"training\": \"\",\n",
      "  \"transformers_version\": \"4.9.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "09/14 09:47:32 AM Loading model /home/mcao610/scratch/huggingface/MNLI/uncased/pytorch_model.bin\n",
      "09/14 09:47:46 AM loading model...\n",
      "09/14 09:47:46 AM done!\n",
      "09/14 09:47:46 AM Weights of TinyBertForSequenceClassification not initialized from pretrained model: ['fit_dense.weight', 'fit_dense.bias']\n",
      "09/14 09:47:46 AM Weights from pretrained model not used in TinyBertForSequenceClassification: ['bert.embeddings.position_ids']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TinyBertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (fit_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model = TinyBertForSequenceClassification.from_pretrained(teacher_model_path, num_labels=num_labels)\n",
    "teacher_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-adrian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  18%|█▊        | 2270/12886 [02:54<13:40, 12.95it/s]"
     ]
    }
   ],
   "source": [
    "cls_features = []\n",
    "example_ids = []\n",
    "\n",
    "for batch_ in tqdm(train_dataloader, desc=\"Evaluating\"):\n",
    "    batch_ = tuple(t.to('cuda') for t in batch_)\n",
    "    with torch.no_grad():\n",
    "        input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch_\n",
    "        logits, atts, reps, pooled = teacher_model(input_ids, segment_ids, input_mask)\n",
    "        \n",
    "        cls_features.append(pooled)\n",
    "        example_ids.append(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cls_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_feature_vectors = torch.cat(cls_features, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_feature_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-fifteen",
   "metadata": {},
   "source": [
    "#### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_feature_numpy = cls_feature_vectors.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b227bf6-991f-4824-96fd-24ed694a70f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label_ids = all_label_ids.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_NUMBER = 4\n",
    "kmeans = KMeans(n_clusters=CLUSTER_NUMBER, random_state=0).fit(cls_feature_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_centers.shape)\n",
    "print(cluster_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890c1f47-3a55-4f82-b05d-382d1956c2bd",
   "metadata": {},
   "source": [
    "#### Save Clustering IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a41ba38-3958-4747-a985-e99b71938c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_guids) == cluster_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c0858b-e3d3-4bc6-8147-5effd3639f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map = {}\n",
    "\n",
    "for guid, l in zip(train_guids, cluster_labels):\n",
    "    cluster_map[guid] = int(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7968c-d730-4261-9ad7-df322c24be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('clusters/cluster_mnli_k{}.json'.format(CLUSTER_NUMBER), 'w') as fp:\n",
    "    json.dump(cluster_map, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-diagnosis",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = cls_feature_numpy[:10000, :]\n",
    "vis_labels = cluster_labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_results = pca.fit_transform(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "cmap = get_cmap(CLUSTER_NUMBER)\n",
    "\n",
    "for k in range(CLUSTER_NUMBER):\n",
    "    cluster_data = vis_labels == k\n",
    "    plt.scatter(pca_results[cluster_data, 0], pca_results[cluster_data, 1],\n",
    "                color=cmap(k), marker='.', s=10)\n",
    "\n",
    "# plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], c='black', s=50)\n",
    "plt.title(\"K-Means (K={})\".format(CLUSTER_NUMBER))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('kmeans.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a926577-c896-47f4-bc60-6dba274fed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_labels = all_label_ids[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe3cb90-41dd-458b-b56b-1fbd6cf77133",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "cmap = ['#4EACC5', '#FF9C34', '#4E9A06']\n",
    "\n",
    "for k in range(3):\n",
    "    cluster_data = vis_labels == k\n",
    "    plt.scatter(pca_results[cluster_data, 0], pca_results[cluster_data, 1],\n",
    "                color=cmap[k], marker='.', s=10)\n",
    "\n",
    "# plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], c='black', s=50)\n",
    "plt.title(\"K-Means (True Label)\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('ture_label.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca5aa46-1abc-4f38-9c3e-d9aaa5212da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge json\n",
    "# train_json = json.load(open('clusters/cluster_mnli_k3_train.json'))\n",
    "# dev_m_json = json.load(open('clusters/cluster_mnli_k3_dev_matched.json'))\n",
    "# dev_mm_json = json.load(open('clusters/cluster_mnli_k3_dev_mismatched.json'))\n",
    "\n",
    "# print(len(train_json))\n",
    "# print(len(dev_m_json))\n",
    "# print(len(dev_mm_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958d7d7f-33c8-499a-b0f8-94d5d4e82330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('clusters/cluster_mnli_k{}.json'.format(CLUSTER_NUMBER), 'w') as fp:\n",
    "#     json.dump({**train_json, **dev_m_json, **dev_mm_json}, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
