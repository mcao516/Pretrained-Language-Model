{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "elect-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from transformer.tokenization import BertTokenizer\n",
    "from transformer.modeling import TinyBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "micro-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from task_distill import (\n",
    "    ColaProcessor,\n",
    "    MnliProcessor,\n",
    "    MnliMismatchedProcessor,\n",
    "    MrpcProcessor,\n",
    "    Sst2Processor,\n",
    "    StsbProcessor,\n",
    "    QqpProcessor,\n",
    "    QnliProcessor,\n",
    "    RteProcessor,\n",
    "    WnliProcessor,\n",
    ")\n",
    "from task_distill import convert_examples_to_features, get_tensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acting-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = {\n",
    "    \"cola\": ColaProcessor,\n",
    "    \"mnli\": MnliProcessor,\n",
    "    \"mnli-mm\": MnliMismatchedProcessor,\n",
    "    \"mrpc\": MrpcProcessor,\n",
    "    \"sst-2\": Sst2Processor,\n",
    "    \"sts-b\": StsbProcessor,\n",
    "    \"qqp\": QqpProcessor,\n",
    "    \"qnli\": QnliProcessor,\n",
    "    \"rte\": RteProcessor,\n",
    "    \"wnli\": WnliProcessor\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "manual-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_modes = {\n",
    "    \"cola\": \"classification\",\n",
    "    \"mnli\": \"classification\",\n",
    "    \"mrpc\": \"classification\",\n",
    "    \"sst-2\": \"classification\",\n",
    "    \"sts-b\": \"regression\",\n",
    "    \"qqp\": \"classification\",\n",
    "    \"qnli\": \"classification\",\n",
    "    \"rte\": \"classification\",\n",
    "    \"wnli\": \"classification\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-wright",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cathedral-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'mnli'\n",
    "processor = processors[task_name]()\n",
    "output_mode = output_modes[task_name]\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)\n",
    "teacher_model_path = '/home/mcao610/scratch/huggingface/MNLI/uncased/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cleared-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/mcao610/scratch/glue_data/MNLI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "absent-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = processor.get_train_examples(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "olympic-wellington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392702"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "manual-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(teacher_model_path, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suitable-texture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15 01:10:30 PM Writing example 0 of 392702\n",
      "08/15 01:10:30 PM *** Example ***\n",
      "08/15 01:10:30 PM guid: train-0\n",
      "08/15 01:10:30 PM tokens: [CLS] conceptual ##ly cream ski ##mming has two basic dimensions - product and geography . [SEP] product and geography are what make cream ski ##mming work . [SEP]\n",
      "08/15 01:10:30 PM input_ids: 101 17158 2135 6949 8301 25057 2038 2048 3937 9646 1011 4031 1998 10505 1012 102 4031 1998 10505 2024 2054 2191 6949 8301 25057 2147 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/15 01:10:30 PM input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/15 01:10:30 PM segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/15 01:10:30 PM label: neutral\n",
      "08/15 01:10:30 PM label_id: 1\n",
      "08/15 01:10:38 PM Writing example 10000 of 392702\n",
      "08/15 01:10:47 PM Writing example 20000 of 392702\n",
      "08/15 01:10:57 PM Writing example 30000 of 392702\n",
      "08/15 01:11:05 PM Writing example 40000 of 392702\n",
      "08/15 01:11:14 PM Writing example 50000 of 392702\n",
      "08/15 01:11:23 PM Writing example 60000 of 392702\n",
      "08/15 01:11:32 PM Writing example 70000 of 392702\n",
      "08/15 01:11:41 PM Writing example 80000 of 392702\n",
      "08/15 01:11:50 PM Writing example 90000 of 392702\n",
      "08/15 01:12:00 PM Writing example 100000 of 392702\n",
      "08/15 01:12:09 PM Writing example 110000 of 392702\n",
      "08/15 01:12:17 PM Writing example 120000 of 392702\n",
      "08/15 01:12:26 PM Writing example 130000 of 392702\n",
      "08/15 01:12:35 PM Writing example 140000 of 392702\n",
      "08/15 01:12:45 PM Writing example 150000 of 392702\n",
      "08/15 01:12:54 PM Writing example 160000 of 392702\n",
      "08/15 01:13:03 PM Writing example 170000 of 392702\n",
      "08/15 01:13:12 PM Writing example 180000 of 392702\n",
      "08/15 01:13:20 PM Writing example 190000 of 392702\n",
      "08/15 01:13:29 PM Writing example 200000 of 392702\n",
      "08/15 01:13:38 PM Writing example 210000 of 392702\n",
      "08/15 01:13:48 PM Writing example 220000 of 392702\n",
      "08/15 01:13:57 PM Writing example 230000 of 392702\n",
      "08/15 01:14:06 PM Writing example 240000 of 392702\n",
      "08/15 01:14:15 PM Writing example 250000 of 392702\n",
      "08/15 01:14:24 PM Writing example 260000 of 392702\n",
      "08/15 01:14:33 PM Writing example 270000 of 392702\n",
      "08/15 01:14:41 PM Writing example 280000 of 392702\n",
      "08/15 01:14:52 PM Writing example 290000 of 392702\n",
      "08/15 01:15:01 PM Writing example 300000 of 392702\n",
      "08/15 01:15:10 PM Writing example 310000 of 392702\n",
      "08/15 01:15:19 PM Writing example 320000 of 392702\n",
      "08/15 01:15:28 PM Writing example 330000 of 392702\n",
      "08/15 01:15:36 PM Writing example 340000 of 392702\n",
      "08/15 01:15:45 PM Writing example 350000 of 392702\n",
      "08/15 01:15:54 PM Writing example 360000 of 392702\n",
      "08/15 01:16:03 PM Writing example 370000 of 392702\n",
      "08/15 01:16:12 PM Writing example 380000 of 392702\n",
      "08/15 01:16:23 PM Writing example 390000 of 392702\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 128\n",
    "train_features = convert_examples_to_features(train_examples, label_list,\n",
    "                                              max_seq_length, tokenizer, output_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "operating-vietnamese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392702\n",
      "<task_distill.InputFeatures object at 0x2afb02a755d0>\n"
     ]
    }
   ],
   "source": [
    "print(len(train_features))\n",
    "print(train_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "overall-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, all_label_ids = get_tensor_data(output_mode, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "following-least",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.TensorDataset"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pursuant-russian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([392702, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "indie-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, sampler=SequentialSampler(train_data), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-airfare",
   "metadata": {},
   "source": [
    "#### Load Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unsigned-candidate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/15 01:16:31 PM Model config {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pre_trained\": \"\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"training\": \"\",\n",
      "  \"transformers_version\": \"4.9.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "08/15 01:16:35 PM Loading model /home/mcao610/scratch/huggingface/MNLI/uncased/pytorch_model.bin\n",
      "08/15 01:16:38 PM loading model...\n",
      "08/15 01:16:38 PM done!\n",
      "08/15 01:16:38 PM Weights of TinyBertForSequenceClassification not initialized from pretrained model: ['fit_dense.weight', 'fit_dense.bias']\n",
      "08/15 01:16:38 PM Weights from pretrained model not used in TinyBertForSequenceClassification: ['bert.embeddings.position_ids']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TinyBertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (fit_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model = TinyBertForSequenceClassification.from_pretrained(teacher_model_path, num_labels=num_labels)\n",
    "teacher_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "grave-adrian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 12272/12272 [15:41<00:00, 13.04it/s]\n"
     ]
    }
   ],
   "source": [
    "cls_features = []\n",
    "\n",
    "for batch_ in tqdm(train_dataloader, desc=\"Evaluating\"):\n",
    "    batch_ = tuple(t.to('cuda') for t in batch_)\n",
    "    with torch.no_grad():\n",
    "        input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch_\n",
    "        logits, atts, reps, pooled = teacher_model(input_ids, segment_ids, input_mask)\n",
    "        \n",
    "        cls_features.append(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dependent-valley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12272"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cls_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "photographic-budapest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "worse-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_feature_vectors = torch.cat(cls_features, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "framed-basketball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([392702, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_feature_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-fifteen",
   "metadata": {},
   "source": [
    "#### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "scheduled-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "least-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "greenhouse-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_feature_numpy = cls_feature_vectors.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "outdoor-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_NUMBER = 10\n",
    "kmeans = KMeans(n_clusters=CLUSTER_NUMBER, random_state=0).fit(cls_feature_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "twenty-ideal",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k_means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ce82e5b92963>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcluster_centers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_means\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'k_means' is not defined"
     ]
    }
   ],
   "source": [
    "cluster_centers = k_means.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_centers.shape)\n",
    "print(cluster_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-diagnosis",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = cls_feature_numpy[:10000, :]\n",
    "vis_labels = cluster_labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_results = pca.fit_transform(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "cmap = get_cmap(CLUSTER_NUMBER)\n",
    "\n",
    "for k in range(CLUSTER_NUMBER):\n",
    "    cluster_data = vis_labels == k\n",
    "    plt.scatter(pca_results[cluster_data, 0], pca_results[cluster_data, 1],\n",
    "                color=cmap(k), marker='.', s=10)\n",
    "\n",
    "plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], c='black', s=50)\n",
    "plt.title(\"K-Means Initialization\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
